{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing as prep\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'cora'\n",
      "C:\\Users\\sbliu\\Desktop\\cora\n"
     ]
    }
   ],
   "source": [
    "cd cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('cora.content', sep ='\\t', header=None)\n",
    "d2 = pd.read_csv('cora.cites', sep ='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- My Implementation ---\n",
    "d1 = (pd.read_csv('cora.content', sep ='\\t', header=None))\n",
    "\n",
    "# Label Encoder\n",
    "le = prep.LabelEncoder()\n",
    "le.fit(d1[1434])\n",
    "d1[1434] = le.transform(d1[1434])\n",
    "\n",
    "# Feature Matrix and Labels\n",
    "d1 = d1.set_index(0)\n",
    "d1 = d1.sort_index()\n",
    "d1 = d1.reset_index()\n",
    "labels = d1[1434]\n",
    "labels = torch.Tensor(labels).long()\n",
    "d1 = d1.drop(columns=[0, 1434])\n",
    "\n",
    "X = np.array(d1)\n",
    "\n",
    "\n",
    "# Create label distibution for LPA\n",
    "\n",
    "labels_distr = np.zeros([len(labels), len(le.classes_)])\n",
    "for row in range(len(labels)):\n",
    "    labels_distr[row][labels[row]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.read_csv('cora.cites', sep ='\\t', header=None)\n",
    "\n",
    "# Adjacency matrix\n",
    "d2 = pd.crosstab(d2[0], d2[1])\n",
    "idx = d2.columns.union(d2.index)\n",
    "d2 = d2.reindex(index = idx, columns = idx, fill_value=0)\n",
    "d2 = d2.reset_index().drop(columns=['index'])\n",
    "d2.columns = np.arange(len(d2.columns))\n",
    "\n",
    "A = np.array(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1.head() # X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d2.head() # A, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Train/Test Sets\n",
    "train_idx = list(d2.sample(frac=.9).index)\n",
    "test_idx = list(set(d2.index) - set(train_idx))\n",
    "\n",
    "train_A = d2.loc[train_idx, train_idx]\n",
    "train_X = d1.loc[train_idx]\n",
    "train_Y = labels[train_idx]\n",
    "\n",
    "test_A = d2.loc[test_idx, test_idx]\n",
    "test_X = d1.loc[test_idx]\n",
    "test_Y = labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregators\n",
    "class Mean_Agg(torch.nn.Module):\n",
    "    '''\n",
    "    GraphSAGE Mean Aggregator\n",
    "    '''\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(Mean_Agg, self).__init__()\n",
    "        \n",
    "        self.fc_x = nn.Linear(in_feats, out_feats)\n",
    "        self.fc_neigh = nn.Linear(in_feats, out_feats)\n",
    "        self.out_feats = out_feats\n",
    "        \n",
    "    def forward(self, x, neigh):\n",
    "        # X: batch of nodes\n",
    "        agg_neigh = neigh.view(x.size(0), -1, neibs.size(1))\n",
    "        agg_neigh = agg_neigh.mean(dim=1)\n",
    "        \n",
    "        output = torch.cat([self.fc_x(x), self.fc_neigh(agg_neigh)], dim=1)\n",
    "        \n",
    "        # Average of Neighborhood feature matrix for each node in batch\n",
    "        return F.relu(output)\n",
    "    \n",
    "class MaxPool_Agg(torch.nn.Module):\n",
    "    '''\n",
    "    GraphSAGE Pooling Aggregator\n",
    "    '''\n",
    "    def __init__(self, in_feasts, out_feats):\n",
    "        ...\n",
    "    \n",
    "    def forward(self, x, neigh):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphSAGE Models and Layers\n",
    "\n",
    "class GS_Layer(torch.nn.Module):\n",
    "    '''\n",
    "    GraphSAGE Layer\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GS_Layer,self).__init__()\n",
    "        ...\n",
    "        \n",
    "    def forward(self, X, steps, A):\n",
    "        # X: batch of nodes\n",
    "        # steps: steps from node for neighborhood\n",
    "        # A: adjacency matrix to find nodes in neighborhood\n",
    "        ...\n",
    "        \n",
    "class GS(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass):\n",
    "        \"\"\"\n",
    "        GraphSAGE Model\n",
    "        \"\"\"\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        '''\n",
    "        gc1 = Aggregator(batch X, neighborhood of X)\n",
    "        gc1 = Layer\n",
    "        gc2 = Aggregator(batch X, neighborhood of X)\n",
    "        gc2 = Layer\n",
    "        '''\n",
    "        \n",
    "    def forward(self, X, A, prep_A):      \n",
    "        X = F.relu(self.gc1(X, A, prep_A))\n",
    "        #x = F.relu(self.gc2(x, adj))\n",
    "        X = self.gc2(X, A, prep_A)\n",
    "        return F.log_softmax(X, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params:\n",
    "# A is the adj matrix\n",
    "# X is the feature matrix\n",
    "class GCN_Layer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(GCN_Layer, self).__init__()\n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.weight = np.random.randn(in_feats, out_feats)\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.weight))\n",
    "\n",
    "    def forward(self, prev_output, A, prep_A=None):\n",
    "        '''\n",
    "        Propogation Rule:\n",
    "        params: pred_A - specify how to prepare A, with or without normalization\n",
    "        '''\n",
    "        prev_output = torch.Tensor(prev_output)\n",
    "        A = torch.Tensor(A)\n",
    "        \n",
    "        right_term = torch.mm(prev_output, self.weight)\n",
    "\n",
    "        # Unnormalized\n",
    "        if prep_A == None:\n",
    "            output = torch.mm(A, right_term)    \n",
    "        # Normalized with Kipf & Welling \n",
    "        elif prep_A == \"norm\":\n",
    "            I = torch.eye(A.shape[0])\n",
    "            A_hat = A + I\n",
    "            D_hat = torch.Tensor(np.diag(A_hat.sum(axis=1) ** (-1/2)))\n",
    "            output = torch.mm(D_hat, A_hat)\n",
    "            output = torch.mm(output, D_hat)\n",
    "            output = torch.mm(output, right_term)\n",
    "            \n",
    "            \n",
    "        return output\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass):\n",
    "        \"\"\"\n",
    "        Simple GCN Model\n",
    "        \"\"\"\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # GCN Layers\n",
    "        self.gc1 = GCN_Layer(nfeat, nhid) \n",
    "        self.gc2 = GCN_Layer(nhid, nclass)\n",
    "        #self.gc3 = GCN_Layer(nhid-300, nclass)\n",
    "        \n",
    "    def forward(self, X, A, prep_A):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        X = F.relu(self.gc1(X, A, prep_A))\n",
    "        #x = F.relu(self.gc2(x, adj))\n",
    "        X = self.gc2(X, A, prep_A)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 7.9106 acc_train: 0.1075 time: 1.6860s\n",
      "Epoch: 0002 loss_train: 7.9106 acc_train: 0.1087 time: 1.8200s\n",
      "Epoch: 0003 loss_train: 7.9106 acc_train: 0.1124 time: 1.6512s\n",
      "Epoch: 0004 loss_train: 7.9106 acc_train: 0.1137 time: 1.5222s\n",
      "Epoch: 0005 loss_train: 7.9106 acc_train: 0.1153 time: 1.5770s\n",
      "Epoch: 0006 loss_train: 7.9106 acc_train: 0.1178 time: 1.5430s\n",
      "Epoch: 0007 loss_train: 7.9106 acc_train: 0.1174 time: 1.5285s\n",
      "Epoch: 0008 loss_train: 7.9106 acc_train: 0.1186 time: 1.5240s\n",
      "Epoch: 0009 loss_train: 7.9106 acc_train: 0.1182 time: 1.5210s\n",
      "Epoch: 0010 loss_train: 7.9106 acc_train: 0.1174 time: 1.5310s\n"
     ]
    }
   ],
   "source": [
    "# LPA-GCN\n",
    "\n",
    "class LPA_GCN_Layer(torch.nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, A):\n",
    "        super(LPA_GCN_Layer, self).__init__()\n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.weight = np.random.randn(in_feats, out_feats)\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.weight))\n",
    "        A = torch.Tensor(A)\n",
    "        self.mask_A = A.clone()\n",
    "        self.mask_A = nn.Parameter(self.mask_A)\n",
    "        \n",
    "    def forward(self, X, A, Y):\n",
    "        X = torch.Tensor(X)\n",
    "        A = torch.Tensor(A)\n",
    "        Y = torch.Tensor(Y)\n",
    "        \n",
    "        right_term = torch.mm(X, self.weight)\n",
    "        # Hadamard A'\n",
    "        A = A * self.mask_A\n",
    "        # Normalize D^-1 * A'\n",
    "        A = F.normalize(A, p=1, dim=1)\n",
    "        \n",
    "        output = torch.mm(A, right_term)\n",
    "        Y_hat = torch.mm(A, Y)\n",
    "        return output, Y_hat\n",
    "    \n",
    "class GCN_LPA(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, A):\n",
    "        super(GCN_LPA, self).__init__()\n",
    "        \n",
    "        self.gcn_lpa1 = LPA_GCN_Layer(nfeat, nhid, A) \n",
    "        self.gcn_lpa2 = LPA_GCN_Layer(nhid, nclass, A) \n",
    "    \n",
    "    def forward(self, X, A, Y):\n",
    "        X, Y_hat = self.gcn_lpa1(X, A, Y)\n",
    "        X = F.relu(X)\n",
    "        X, Y_hat = self.gcn_lpa2(X, A, Y_hat)        \n",
    "        return F.relu(X), F.relu(Y_hat)\n",
    "        \n",
    "GCN_LPA_model = GCN_LPA(X.shape[1], 300, len(le.classes_), A )\n",
    "optimizer = torch.optim.SGD(GCN_LPA_model.parameters(), lr=.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "Lambda = 0\n",
    "epochs = 10\n",
    "for epoch in np.arange(epochs):\n",
    "    t = time.time()\n",
    "    GCN_LPA_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output, Y_hat = GCN_LPA_model(X, A, labels_distr)\n",
    "    \n",
    "    loss_gcn = criterion(output[train_idx], labels[train_idx])\n",
    "    loss_lpa = criterion(Y_hat[train_idx], labels[train_idx])\n",
    "\n",
    "    acc = accuracy(output[train_idx], labels[train_idx])\n",
    "    loss_train = loss_gcn + Lambda * loss_lpa\n",
    "\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss.item()),\n",
    "          'acc_train: {:.4f}'.format(acc.item()), \n",
    "          'time: {:.4f}s'.format(time.time() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and Optimizer\n",
    "\n",
    "# GCN takes in number of papers, number hidden layers, and number of classes\n",
    "model = GCN(X.shape[1], 300, len(le.classes_))\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.1)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test functions\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "def train(epoch, prep_A = None):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X, A, prep_A)\n",
    "    loss = criterion(output[train_idx], labels[train_idx])\n",
    "    acc = accuracy(output[train_idx], labels[train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss.item()),\n",
    "          'acc_train: {:.4f}'.format(acc.item()), \n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    \n",
    "def test(prep_A = None):\n",
    "    model.eval()\n",
    "    output = model(X, A, prep_A)\n",
    "    loss_test = criterion(output[test_idx], labels[test_idx])\n",
    "    acc_test = accuracy(output[test_idx], labels[test_idx])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "def run(epochs, prep_A):\n",
    "    t_total = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        train(epoch, prep_A)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    # Testing\n",
    "    test(prep_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 6.4959 acc_train: 0.7403 time: 3.3290s\n",
      "Epoch: 0002 loss_train: 6.4316 acc_train: 0.7444 time: 4.0761s\n",
      "Epoch: 0003 loss_train: 6.3684 acc_train: 0.7452 time: 3.7678s\n",
      "Epoch: 0004 loss_train: 6.3062 acc_train: 0.7476 time: 4.2556s\n",
      "Epoch: 0005 loss_train: 6.2450 acc_train: 0.7497 time: 3.6705s\n",
      "Epoch: 0006 loss_train: 6.1847 acc_train: 0.7501 time: 3.8601s\n",
      "Epoch: 0007 loss_train: 6.1253 acc_train: 0.7509 time: 4.2255s\n",
      "Epoch: 0008 loss_train: 6.0668 acc_train: 0.7513 time: 4.0200s\n",
      "Epoch: 0009 loss_train: 6.0092 acc_train: 0.7526 time: 3.1720s\n",
      "Epoch: 0010 loss_train: 5.9524 acc_train: 0.7534 time: 3.4846s\n",
      "Epoch: 0011 loss_train: 5.8964 acc_train: 0.7550 time: 3.2866s\n",
      "Epoch: 0012 loss_train: 5.8412 acc_train: 0.7571 time: 3.1036s\n",
      "Epoch: 0013 loss_train: 5.7868 acc_train: 0.7591 time: 3.3726s\n",
      "Epoch: 0014 loss_train: 5.7331 acc_train: 0.7595 time: 3.8710s\n",
      "Epoch: 0015 loss_train: 5.6800 acc_train: 0.7604 time: 3.8928s\n",
      "Epoch: 0016 loss_train: 5.6277 acc_train: 0.7624 time: 3.6770s\n",
      "Epoch: 0017 loss_train: 5.5760 acc_train: 0.7628 time: 3.7143s\n",
      "Epoch: 0018 loss_train: 5.5249 acc_train: 0.7632 time: 4.1351s\n",
      "Epoch: 0019 loss_train: 5.4745 acc_train: 0.7653 time: 3.9390s\n",
      "Epoch: 0020 loss_train: 5.4247 acc_train: 0.7669 time: 3.7780s\n",
      "Epoch: 0021 loss_train: 5.3756 acc_train: 0.7690 time: 3.3995s\n",
      "Epoch: 0022 loss_train: 5.3270 acc_train: 0.7698 time: 3.4851s\n",
      "Epoch: 0023 loss_train: 5.2791 acc_train: 0.7686 time: 3.4383s\n",
      "Epoch: 0024 loss_train: 5.2316 acc_train: 0.7698 time: 3.5820s\n",
      "Epoch: 0025 loss_train: 5.1847 acc_train: 0.7710 time: 3.6470s\n",
      "Epoch: 0026 loss_train: 5.1383 acc_train: 0.7723 time: 3.6300s\n",
      "Epoch: 0027 loss_train: 5.0925 acc_train: 0.7743 time: 3.3220s\n",
      "Epoch: 0028 loss_train: 5.0473 acc_train: 0.7735 time: 3.2512s\n",
      "Epoch: 0029 loss_train: 5.0029 acc_train: 0.7755 time: 3.2092s\n",
      "Epoch: 0030 loss_train: 4.9594 acc_train: 0.7764 time: 3.1465s\n",
      "Epoch: 0031 loss_train: 4.9174 acc_train: 0.7764 time: 3.4005s\n",
      "Epoch: 0032 loss_train: 4.8772 acc_train: 0.7747 time: 3.2146s\n",
      "Epoch: 0033 loss_train: 4.8410 acc_train: 0.7760 time: 3.3270s\n",
      "Epoch: 0034 loss_train: 4.8073 acc_train: 0.7727 time: 3.5220s\n",
      "Epoch: 0035 loss_train: 4.7824 acc_train: 0.7760 time: 3.8630s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-62483f30c6d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'norm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-acf6ecce970f>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(epochs, prep_A)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mt_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprep_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Optimization Finished!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total time elapsed: {:.4f}s\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-3c651d47a9c8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, prep_A)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprep_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sbliu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-1380c87f3f49>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X, A, prep_A)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprep_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m#x = F.relu(self.gc2(x, adj))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprep_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sbliu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-1380c87f3f49>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, prev_output, A, prep_A)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mD_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run(10, 'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
